---SERVER--- : Samples per worker = 3750.0, batches_per_worker = 15, updates_per_worker = 45, total_updates = 360
--------------------------------------------------------------------------
A process has executed an operation involving a call to the
"fork()" system call to create a child process.  Open MPI is currently
operating in a condition that could result in memory corruption or
other system errors; your job may hang, crash, or produce silent
data corruption.  The use of fork() (or system() or other calls that
create child processes) is strongly discouraged.

The process that invoked fork was:

  Local host:          [[61090,1],3] (PID 9756)

If you are *absolutely sure* that your application will successfully
and correctly survive a call to fork(), you may disable this warning
by setting the mpi_warn_on_fork MCA parameter to 0.
--------------------------------------------------------------------------
---CLIENT 6 --- : Training Epoch: 0 done.  Loss: 0.502, Prec@1: 0.735, Prec@3: 0.516, train_time = 34.308 

---CLIENT 8 --- : Training Epoch: 0 done.  Loss: 0.512, Prec@1: 0.691, Prec@3: 0.494, train_time = 35.111 

---CLIENT 7 --- : Training Epoch: 0 done.  Loss: 0.462, Prec@1: 0.742, Prec@3: 0.505, train_time = 35.371 

---CLIENT 5 --- : Training Epoch: 0 done.  Loss: 0.402, Prec@1: 0.811, Prec@3: 0.516, train_time = 42.739 

---CLIENT 2 --- : Training Epoch: 0 done.  Loss: 0.404, Prec@1: 0.849, Prec@3: 0.545, train_time = 43.583 

---CLIENT 4 --- : Training Epoch: 0 done.  Loss: 0.398, Prec@1: 0.838, Prec@3: 0.548, train_time = 43.740 

---CLIENT 3 --- : Training Epoch: 0 done.  Loss: 0.527, Prec@1: 0.825, Prec@3: 0.537, train_time = 43.827 

---CLIENT 1 --- : Training Epoch: 0 done.  Loss: 0.434, Prec@1: 0.811, Prec@3: 0.563, train_time = 46.293 

---CLIENT 6 --- : Training Epoch: 1 done.  Loss: 0.303, Prec@1: 0.838, Prec@3: 0.647, train_time = 34.695 

---CLIENT 7 --- : Training Epoch: 1 done.  Loss: 0.300, Prec@1: 0.855, Prec@3: 0.643, train_time = 35.043 

---CLIENT 8 --- : Training Epoch: 1 done.  Loss: 0.298, Prec@1: 0.850, Prec@3: 0.640, train_time = 35.143 

---CLIENT 4 --- : Training Epoch: 1 done.  Loss: 0.288, Prec@1: 0.890, Prec@3: 0.643, train_time = 40.525 

---CLIENT 5 --- : Training Epoch: 1 done.  Loss: 0.284, Prec@1: 0.891, Prec@3: 0.640, train_time = 42.371 

---CLIENT 2 --- : Training Epoch: 1 done.  Loss: 0.281, Prec@1: 0.891, Prec@3: 0.635, train_time = 43.774 

---CLIENT 1 --- : Training Epoch: 1 done.  Loss: 0.286, Prec@1: 0.910, Prec@3: 0.630, train_time = 45.547 

---CLIENT 3 --- : Training Epoch: 1 done.  Loss: 0.280, Prec@1: 0.902, Prec@3: 0.642, train_time = 46.536 

---CLIENT 7 --- : Training Epoch: 2 done.  Loss: 0.263, Prec@1: 0.925, Prec@3: 0.643, train_time = 35.533 

---CLIENT 8 --- : Training Epoch: 2 done.  Loss: 0.260, Prec@1: 0.924, Prec@3: 0.640, train_time = 35.877 

---CLIENT 4 --- : Training Epoch: 2 done.  Loss: 0.259, Prec@1: 0.926, Prec@3: 0.648, train_time = 42.572 

---CLIENT 2 --- : Training Epoch: 2 done.  Loss: 0.258, Prec@1: 0.925, Prec@3: 0.644, train_time = 43.430 

---CLIENT 5 --- : Training Epoch: 2 done.  Loss: 0.255, Prec@1: 0.931, Prec@3: 0.646, train_time = 43.502 

---CLIENT 6 --- : Training Epoch: 2 done.  Loss: 0.260, Prec@1: 0.924, Prec@3: 0.648, train_time = 45.306 

---CLIENT 1 --- : Training Epoch: 2 done.  Loss: 0.262, Prec@1: 0.927, Prec@3: 0.637, train_time = 45.318 

---CLIENT 3 --- : Training Epoch: 2 done.  Loss: 0.261, Prec@1: 0.925, Prec@3: 0.648, train_time = 46.228 

---CLIENT 7 --- : Training Epoch: 3 done.  Loss: 0.261, Prec@1: 0.925, Prec@3: 0.643, train_time = 35.164 

---CLIENT 8 --- : Training Epoch: 3 done.  Loss: 0.258, Prec@1: 0.924, Prec@3: 0.640, train_time = 35.281 

---CLIENT 4 --- : Training Epoch: 3 done.  Loss: 0.257, Prec@1: 0.926, Prec@3: 0.648, train_time = 41.735 

---CLIENT 5 --- : Training Epoch: 3 done.  Loss: 0.253, Prec@1: 0.931, Prec@3: 0.646, train_time = 42.767 

---CLIENT 2 --- : Training Epoch: 3 done.  Loss: 0.257, Prec@1: 0.925, Prec@3: 0.644, train_time = 43.765 

---CLIENT 6 --- : Training Epoch: 3 done.  Loss: 0.258, Prec@1: 0.924, Prec@3: 0.648, train_time = 45.127 

---CLIENT 1 --- : Training Epoch: 3 done.  Loss: 0.260, Prec@1: 0.927, Prec@3: 0.637, train_time = 45.418 

---CLIENT 3 --- : Training Epoch: 3 done.  Loss: 0.259, Prec@1: 0.925, Prec@3: 0.648, train_time = 47.145 

---CLIENT 7 --- : Training Epoch: 4 done.  Loss: 0.261, Prec@1: 0.925, Prec@3: 0.643, train_time = 35.729 

---CLIENT 8 --- : Training Epoch: 4 done.  Loss: 0.258, Prec@1: 0.924, Prec@3: 0.640, train_time = 36.221 

---CLIENT 4 --- : Training Epoch: 4 done.  Loss: 0.257, Prec@1: 0.926, Prec@3: 0.648, train_time = 43.702 

---CLIENT 5 --- : Training Epoch: 4 done.  Loss: 0.253, Prec@1: 0.931, Prec@3: 0.646, train_time = 43.699 

---CLIENT 2 --- : Training Epoch: 4 done.  Loss: 0.257, Prec@1: 0.925, Prec@3: 0.644, train_time = 43.784 

---CLIENT 6 --- : Training Epoch: 4 done.  Loss: 0.259, Prec@1: 0.924, Prec@3: 0.648, train_time = 45.635 

---CLIENT 1 --- : Training Epoch: 4 done.  Loss: 0.260, Prec@1: 0.927, Prec@3: 0.637, train_time = 45.720 

---CLIENT 3 --- : Training Epoch: 4 done.  Loss: 0.259, Prec@1: 0.925, Prec@3: 0.648, train_time = 46.336 

---CLIENT 3 --- : Last epoch stats : Loss: 0.259, Prec@1: 0.925, Prec@3: 0.648, total_exec_time = 232.706
---CLIENT 2 --- : Last epoch stats : Loss: 0.257, Prec@1: 0.925, Prec@3: 0.644, total_exec_time = 232.714
---CLIENT 4 --- : Last epoch stats : Loss: 0.257, Prec@1: 0.926, Prec@3: 0.648, total_exec_time = 232.721
---CLIENT 5 --- : Last epoch stats : Loss: 0.253, Prec@1: 0.931, Prec@3: 0.646, total_exec_time = 232.729
---CLIENT 6 --- : Last epoch stats : Loss: 0.259, Prec@1: 0.924, Prec@3: 0.648, total_exec_time = 232.737
---CLIENT 7 --- : Last epoch stats : Loss: 0.261, Prec@1: 0.925, Prec@3: 0.643, total_exec_time = 232.740
---CLIENT 8 --- : Last epoch stats : Loss: 0.258, Prec@1: 0.924, Prec@3: 0.640, total_exec_time = 232.749
---SERVER--- : Work done. Exiting.
---CLIENT 1 --- : Last epoch stats : Loss: 0.260, Prec@1: 0.927, Prec@3: 0.637, total_exec_time = 232.759
---CLIENT 7 --- : All reduce results weighted_loss = 0.258, precision_1 = 0.926, precision_3 = 0.644
---CLIENT 8 --- : All reduce results weighted_loss = 0.258, precision_1 = 0.926, precision_3 = 0.644
---CLIENT 1 --- : All reduce results weighted_loss = 0.258, precision_1 = 0.926, precision_3 = 0.644
---CLIENT {} --- : Done with processing for worker. EXITING
---CLIENT {} --- : Done with processing for worker. EXITING
---CLIENT 5 --- : All reduce results weighted_loss = 0.258, precision_1 = 0.926, precision_3 = 0.644
---CLIENT 3 --- : All reduce results weighted_loss = 0.258, precision_1 = 0.926, precision_3 = 0.644
---CLIENT {} --- : Done with processing for worker. EXITING
---CLIENT {} --- : Done with processing for worker. EXITING
---CLIENT 2 --- : All reduce results weighted_loss = 0.258, precision_1 = 0.926, precision_3 = 0.644
---CLIENT 4 --- : All reduce results weighted_loss = 0.258, precision_1 = 0.926, precision_3 = 0.644
---CLIENT {} --- : Done with processing for worker. EXITING
---CLIENT 6 --- : All reduce results weighted_loss = 0.258, precision_1 = 0.926, precision_3 = 0.644
---CLIENT {} --- : Done with processing for worker. EXITING
---CLIENT {} --- : Done with processing for worker. EXITING
---CLIENT {} --- : Done with processing for worker. EXITING
